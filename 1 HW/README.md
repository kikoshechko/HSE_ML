# Домашнее задание HW_1 — Машинное обучение с регрессией

**Предобработка данных**
- Загрузка тренировочного и тестового наборов.
- Обнаружение и удаление явных и скрытных дубликатов.
- Обработка пропущенных значений: числовые признаки заполнялись медианой (рассчитанной на train) для согласованности с тестовым набором.
- Преобразование признаков mileage, engine, max_power в числовой формат (убирала лишний текст, который мешал стать им числовыми); удаление столбца torque для упрощения.
- Приведение типов engine и seats к int.

**Анализ данных**
- Получение основных статистик по числовым и категориальным признакам.
- Визуализация распределений признаков через pairplot.
- Анализ корреляций между признаками: сильная положительная зависимость между max_power и selling_price. Также можно было на том этапе сделать вывод, что чем больше прокат машины, тем она более старая (раньше год выпуска)

**Формирование признаков для моделей**
- Сначала была работа над вещественными признаками (не сильно успешная): year, km_driven, mileage, engine, max_power, seats.
- Потом было кодирование кат признаков методом OneHotEncoding с удалением первого столбца для предотвращения мультиколлинеарности - успешная тактика.

**Обучение моделей и оценка качества**
Были обучены следующие модели: 
- Линейная регрессия (без масштабирования)
- Линейная регрессия + StandardScaler
- Lasso (без и с GridSearchCV)
- ElasticNet
- Ridge (с OHE-кодированием категориальных признаков)

После все модели были сохранены в формате .pkl для дальнейшего использования в приложении STREAMLIT.

**Выводы*:**
- Наибольший прирост качества дала, несомненно работа с OHE-кодированием категориальных признаков.
- Линейная регрессия на чистых вещественных признаках ограничена по качеству.
- Некоторые задачи, например, обработка столбца torque или использование name, остались нереализованными для упрощения модели.
- Использование StandardScaler и регуляризации позволило интерпретировать важность признаков и избежать переобучения.
